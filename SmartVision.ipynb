{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anugrahjosiahgupta/CurserInteraction/blob/main/SmartVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQz28h3gFmcQ",
        "outputId": "21220dcb-f76c-4dd2-89cf-b69b3beb9267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " affidavit.pdf\t\t\t   'real CV (1).gdoc'\n",
            "'Colab Notebooks'\t\t   'real CV.gdoc'\n",
            " datasets\t\t\t   'Resume march 2025 (1).docx'\n",
            " IMG-20240908-WA0003.jpg\t   'Resume march 2025.docx'\n",
            " josh.pdf\t\t\t   'Resume march 2025.pdf'\n",
            "'Josh resume.gdoc'\t\t    Untitled\n",
            "'Josh resume.pdf'\t\t   'Untitled document.gdoc'\n",
            "'My signature _240827_223308.jpg'\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/MyDrive\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/datasets\n",
        "!ls /content/drive/MyDrive/datasets/processed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnSmjgyVOHFC",
        "outputId": "d2340beb-9c7e-4e6b-ec49-dc75faef9488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed\n",
            "final_model.h5\tfreshcucumber  freshtamto    rottenbanana    rottenpatato\n",
            "freshapples\tfreshoranges   products      rottencucumber  rottentamto\n",
            "freshbanana\tfreshpatato    rottenapples  rottenoranges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cbemGlxIK8L",
        "outputId": "c642a5f5-d5a5-424c-8398-fbe35b250f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls /content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU43_eoaJtuR",
        "outputId": "42868d72-1451-4133-e46e-317a608f496e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'config.yaml': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm config.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2gTC82rKL4K"
      },
      "outputs": [],
      "source": [
        "with open(\"config.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\"\"paths:\n",
        "  freshness_train: \"/content/drive/MyDrive/datasets/train\"\n",
        "  freshness_val: \"/content/drive/MyDrive/datasets/test\"\n",
        "  object_train: \"/content/drive/MyDrive/datasets/train\"\n",
        "  object_model: \"/content/models/object_model.joblib\"\n",
        "  freshness_model: \"/content/models/freshness_model.keras\"\n",
        "  processed_data: \"/content/drive/MyDrive/datasets/processed\"\n",
        "\n",
        "logging:\n",
        "  file: \"/content/logs/pipeline_log.txt\"\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NOocHdTfKSzS",
        "outputId": "15cf4691-e54e-448b-ad1e-9448bfe4d70d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/main.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7Te4XvXCc_L8",
        "outputId": "504725db-9bfd-4874-8f07-eb123e287e38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'config.yaml', 'drive', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Check contents of the current working directory\n",
        "os.listdir()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo6dN0iAfCiq",
        "outputId": "305cc01a-cad2-4bb8-ee06-fb4f6389608b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoCM9B-efk-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472ca3be-bf73-4913-c01f-2aed13aabeb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Resume march 2025.pdf', 'Josh resume.gdoc', 'My signature _240827_223308.jpg', 'IMG-20240908-WA0003.jpg', 'affidavit.pdf', 'Josh resume.pdf', 'josh.pdf', 'Resume march 2025 (1).docx', 'Resume march 2025.docx', 'Untitled document.gdoc', 'Colab Notebooks', 'datasets', 'Untitled', 'real CV (1).gdoc', 'real CV.gdoc']\n",
            "['processed']\n",
            "['freshapples', 'freshbanana', 'freshcucumber', 'freshtamto', 'products', 'freshpatato', 'freshoranges', 'rottenbanana', 'rottenapples', 'rottencucumber', 'rottenpatato', 'rottenoranges', 'rottentamto', 'final_model.h5']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Check if Google Drive is mounted\n",
        "print(os.listdir(\"/content/drive/MyDrive\"))\n",
        "\n",
        "# Check inside your 'datasets' folder\n",
        "print(os.listdir(\"/content/drive/MyDrive/datasets\"))\n",
        "\n",
        "# Check inside 'processed'\n",
        "print(os.listdir(\"/content/drive/MyDrive/datasets/processed\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Och56UtPgJGu",
        "outputId": "1985bd8c-93b8-4cd1-cff1-0f0fb9997195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files inside processed folder: ['freshapples', 'freshbanana', 'freshcucumber', 'freshtamto', 'products', 'freshpatato', 'freshoranges', 'rottenbanana', 'rottenapples', 'rottencucumber', 'rottenpatato', 'rottenoranges', 'rottentamto', 'final_model.h5']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/datasets/processed\"\n",
        "print(\"Files inside processed folder:\", os.listdir(folder_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In7ZtLWPiWXp",
        "outputId": "796fa20d-2914-4a4c-df51-df59eadc7594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4455 images belonging to 13 classes.\n",
            "Found 1111 images belonging to 13 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m 10/140\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29:19\u001b[0m 14s/step - accuracy: 0.1366 - loss: 2.8201"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Path to your processed folder\n",
        "data_dir = \"/content/drive/MyDrive/datasets/processed\"\n",
        "\n",
        "# Image settings\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Data preprocessing and augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Save model\n",
        "model.save(\"/content/drive/MyDrive/datasets/processed/final_model.h5\")\n",
        "print(\"✅ Training complete and model saved as 'final_model.h5'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh1S4fozjmns"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import random\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkaiBU3YjuYm"
      },
      "outputs": [],
      "source": [
        "# Load your model\n",
        "model_path = \"/content/drive/MyDrive/datasets/processed/final_model.h5\"\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Load face detection model from OpenCV (Haar Cascade)\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Define product fun facts\n",
        "fun_facts = {\n",
        "    \"apple\": \"Apples are 25% air, which is why they float!\",\n",
        "    \"banana\": \"Bananas are berries, but strawberries are not!\",\n",
        "    \"orange\": \"Oranges are actually a hybrid between tangerines and pomelos.\",\n",
        "    \"cucumber\": \"Cucumbers are made up of 95% water!\",\n",
        "    \"tomato\": \"Tomatoes are a fruit, not a vegetable!\",\n",
        "    \"potato\": \"Potatoes were the first vegetable grown in space!\"\n",
        "    # Add more as necessary\n",
        "}\n",
        "\n",
        "# Initialize webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    # Read frame from webcam\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert to RGB (model expects RGB, OpenCV captures BGR)\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Prepare image for prediction\n",
        "    img = cv2.resize(rgb_frame, (224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Normalize\n",
        "\n",
        "    # Predict the product\n",
        "    predictions = model.predict(img_array)\n",
        "    class_idx = np.argmax(predictions, axis=1)[0]\n",
        "    confidence = predictions[0][class_idx]\n",
        "    product_name = list(train_generator.class_indices.keys())[class_idx]\n",
        "\n",
        "    # Display the prediction (fresh/rotten)\n",
        "    if \"fresh\" in product_name:\n",
        "        label = f\"{product_name} - Fresh!\"\n",
        "        freshness = confidence\n",
        "    else:\n",
        "        label = f\"{product_name} - Rotten!\"\n",
        "        freshness = confidence\n",
        "\n",
        "    # Display freshness percentage\n",
        "    percentage = f\"Freshness: {f'{freshness*100:.2f}'}%\"\n",
        "\n",
        "    # Draw label and percentage\n",
        "    cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    cv2.putText(frame, percentage, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "    # Display fun fact\n",
        "    fun_fact = fun_facts.get(product_name.split()[1], \"No fun fact available.\")\n",
        "    cv2.putText(frame, f\"Fun Fact: {fun_fact}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
        "\n",
        "    # Detect faces in the frame\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    # If a face is detected, predict attractiveness and suggest a fruit\n",
        "    if len(faces) > 0:\n",
        "        for (x, y, w, h) in faces:\n",
        "            face = frame[y:y+h, x:x+w]\n",
        "\n",
        "            # Attractiveness (using a dummy prediction model)\n",
        "            attractiveness = random.uniform(60, 100)  # Placeholder (can be replaced by a real model)\n",
        "            fruit_suggestion = random.choice([\"apple\", \"banana\", \"orange\", \"cucumber\", \"tomato\", \"potato\"])\n",
        "            cv2.putText(frame, f\"Attractiveness: {attractiveness:.1f}%\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "            cv2.putText(frame, f\"Try eating: {fruit_suggestion.capitalize()}\", (x, y+h+10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "\n",
        "    # Show the frame\n",
        "    cv2.imshow(\"Product Quality Detection\", frame)\n",
        "\n",
        "    # Break loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the camera and close any OpenCV windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5Ls7It1nbWc",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from google.colab.patches import cv2_imshow\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Load trained model\n",
        "model = load_model(\"/content/drive/MyDrive/datasets/processed/final_model.h5\")\n",
        "\n",
        "# Class labels\n",
        "class_labels = ['freshbanana', 'freshapples', 'freshtamto', 'freshpatato', 'freshoranges', 'freshokra', 'freshcucumber',\n",
        "                'rottenbanana', 'rottenapples', 'rottentamto', 'rottenpatato', 'rottenoranges', 'rottencucumber']\n",
        "\n",
        "# Fun facts\n",
        "fun_facts = {\n",
        "    'banana': \"Bananas are berries, but strawberries are not!\",\n",
        "    'apple': \"Apples float because 25% of their volume is air!\",\n",
        "    'tamto': \"Tomatoes were once considered poisonous in Europe.\",\n",
        "    'patato': \"Potatoes were the first vegetable grown in space!\",\n",
        "    'oranges': \"Oranges were originally green in color!\",\n",
        "    'okra': \"Okra seeds are sometimes roasted and used as a coffee substitute.\",\n",
        "    'cucumber': \"Cucumbers are 96% water!\"\n",
        "}\n",
        "\n",
        "# Fruit suggestions for faces\n",
        "fruit_suggestions = ['banana', 'apple', 'tamto', 'patato', 'oranges', 'okra', 'cucumber']\n",
        "\n",
        "# Load Haar Cascade for face detection\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "# Start camera\n",
        "cap = cv2.VideoCapture(0)  # Use 0 for webcam\n",
        "\n",
        "print(\"📷 Starting camera... show a product or your face!\")\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    orig = frame.copy()\n",
        "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
        "\n",
        "    detected = False\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        detected = True\n",
        "        face = frame[y:y+h, x:x+w]\n",
        "        attractiveness = random.randint(60, 100)\n",
        "        suggestion = random.choice(fruit_suggestions)\n",
        "\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "        cv2.putText(frame, f\"Attractive: {attractiveness}%\", (x, y - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "        cv2.putText(frame, f\"Try eating more {suggestion}!\", (x, y + h + 20),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "\n",
        "    if not detected:\n",
        "        # Assume product detection if no face\n",
        "        img = cv2.resize(orig, (224, 224))\n",
        "        img = img.astype(\"float\") / 255.0\n",
        "        img = img_to_array(img)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "\n",
        "        prediction = model.predict(img)[0]\n",
        "        max_index = np.argmax(prediction)\n",
        "        label = class_labels[max_index]\n",
        "        confidence = round(prediction[max_index] * 100, 2)\n",
        "\n",
        "        is_fresh = \"fresh\" in label\n",
        "        fruit = ''.join([char for char in label if not char.isnumeric()]).replace(\"fresh\", \"\").replace(\"rotten\", \"\")\n",
        "        fruit = fruit.strip()\n",
        "\n",
        "        safe = \"✅ Safe to eat\" if is_fresh else \"⚠️ Not safe\"\n",
        "        verdict = \"Fresh\" if is_fresh else \"Rotten\"\n",
        "\n",
        "        # Draw rectangle and prediction\n",
        "        cv2.rectangle(frame, (10, 30), (400, 140), (0, 0, 255), 2)\n",
        "        cv2.putText(frame, f\"{verdict} {fruit}\", (20, 50),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, f\"Confidence: {confidence}%\", (20, 80),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, safe, (20, 110),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0) if is_fresh else (0, 0, 255), 2)\n",
        "        cv2.putText(frame, \"Fact: \" + fun_facts.get(fruit, \"No fact found.\"), (20, 140),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1)\n",
        "\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    # Wait key for stop\n",
        "    key = cv2.waitKey(1)\n",
        "    if key == ord(\"q\"):\n",
        "        print(\"👋 Exiting...\")\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOEBuOPpmW7u/Ig5wF15oYz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}